# Лекция "Морфологическая обработка: Введение и основные концепции"

## 1. Морфологическая обработка
Морфологическая обработка - это процесс анализа и обработки словоформ для извлечения грамматической информации (например, части речи, склонения, спряжения и т. д.) и приведения слова к базовой форме (лемматизация или стемминг). Она играет важную роль в обработке естественного языка (NLP) и широко используется в поисковых системах, чат-ботах, анализе текста и других приложениях.

### 1. Основные задачи морфологической обработки

- 1. **Лемматизация** — приведение слова к его базовой форме (лемме).
- 2. **Стемминг** — отсечение окончаний для получения основы слова.
- 3. **Анализ частей речи (POS-tagging)** — определение грамматической категории слова.
- 4. **Разбор морфологических характеристик** — определение падежа, числа, рода и других атрибутов.

### 2. Библиотеки для морфологической обработки в Python

Для работы с морфологией в Python используются библиотеки, такие как:

- **pymorphy2** — мощная библиотека для морфологического анализа русского языка.
- **NLTK** — библиотека для обработки текста, поддерживающая английский и другие языки.
- **spaCy** — современный инструмент для NLP с поддержкой лемматизации.
- **Stanza** — библиотека от команды Stanford NLP.

### 3. Установка необходимых библиотек

*pip install pymorphy2*

*pip install spacy*

**4. Пример работы с pymorphy2:**

*import pymorphy2*

*# Создаем объект MorphAnalyzer*

*morph = pymorphy2.MorphAnalyzer()*

*# Анализируем слово*

*word = "бегущие"*

*parsed\_word = morph.parse(word)[0]  # Берем первый вариант разбора*

*# Выводим информацию*

*print(f"Слово: {word}")*

*print(f"Лемма: {parsed\_word.normal\_form}")*

*print(f"Часть речи: {parsed\_word.tag.POS}")*

*print(f"Падеж: {parsed\_word.tag.case}")*

*print(f"Число: {parsed\_word.tag.number}")*

Результат выполнения кода:

*Слово: бегущие*

*Лемма: бежать*

*Часть речи: VERB*

*Падеж: None*

*Число: plur*

**Объяснение:**

- normal\_form возвращает лемму слова — "бежать".
- tag.POS определяет часть речи — глагол (VERB).
- tag.case показывает, что падежа у слова нет, так как это форма глагола.
- tag.number указывает число — множественное (plur).

### 5. Пример использования лемматизации в анализе текста:

def lemmatize\_text(text):

`    `"""Лемматизация текста на русском языке."""

`    `morph = pymorphy2.MorphAnalyzer()

`    `words = text.split()  # Простое разбиение текста на слова

`    `lemmatized\_words = [morph.parse(word)[0].normal\_form for word in words]

`    `return " ".join(lemmatized\_words)

\# Пример текста

text = "Машины едут по дороге, а люди идут по тротуару."

lemmatized = lemmatize\_text(text)

print(f"Оригинал: {text}")

print(f"Лемматизированный текст: {lemmatized}")

Результат:

Оригинал: Машины едут по дороге, а люди идут по тротуару.

Лемматизированный текст: машина ехать по дорога, а человек идти по тротуар.


**Объяснение:**

- Текст разбивается на слова, каждое из которых приводится к лемме.
- Пример показывает, как преобразовать текст в форму, удобную для анализа, например, для поиска или машинного обучения.


### 6. Стемминг и его использование

Стемминг — это процесс удаления окончаний из слова с целью нахождения его основы (стема). В отличие от лемматизации, стемминг не всегда приводит слово к полноценной лексической форме, а просто отсеивает окончания. Этот метод обычно быстрее и проще, но менее точен.

**1. Принцип работы стемминга**

Стемминг обычно работает на основе заранее определённых правил или словарей. Он помогает уменьшить количество уникальных форм слова (например, "бегать", "бегаю", "бежал" можно привести к одному стему — "бег").

**2. Стемминг в Python**

Для стемминга русского языка можно использовать библиотеку **snowballstemmer**, которая поддерживает множество языков, включая русский.

**3. Установка snowballstemmer**

*pip install snowballstemmer*

**4. Пример стемминга с использованием snowballstemmer**

*import snowballstemmer*

*# Создаем объект для русского языка*

*stemmer = snowballstemmer.RussianStemmer()*

*# Пример слов*

*words = ["бегать", "бегаю", "бежал", "беги", "бегущие"]*

*# Стемминг слов*

*stems = [stemmer.stemWord(word) for word in words]* (было: "stemmer.stem(word)")

*print(f"Оригинальные слова: {words}")*

*print(f"После стемминга: {stems}")*

Результат:

*Оригинальные слова: ['бегать', 'бегаю', 'бежал', 'беги', 'бегущие']*

*После стемминга: ['бег', 'бег', 'бег', 'бег', 'бег']*

**Объяснение:**

- Все слова приводятся к единому стему — "бег", независимо от их формы.
- Это позволяет уменьшить разнообразие форм, с которыми нужно работать в дальнейших задачах анализа текста.


**5. Преимущества и недостатки стемминга**

**Преимущества:**

- Быстрота выполнения: стемминг обычно работает быстрее, чем лемматизация.
- Простота реализации.

**Недостатки:**

- Потеря точности: стемминг может привести к искажению смысла, так как не всегда сохраняется грамматическая корректность.
- Стемминг может не учитывать контекст и многозначность слов.

**6. Пример использования стемминга в анализе текста**

Предположим, что у нас есть текст, и нам нужно привести все формы глаголов к их основе для дальнейшего анализа.

*def stem\_text(text):*

`    `*"""Стемминг текста на русском языке."""*

`    `*stemmer = snowballstemmer.RussianStemmer()*

`    `*words = text.split()  # Простое разбиение текста на слова*

`    `*stemmed\_words = [stemmer.stem(word) for word in words]*

`    `*return " ".join(stemmed\_words)*

*# Пример текста*

*text = "Дети бегают по парку и играют на качелях."*

*stemmed = stem\_text(text)*

*print(f"Оригинал: {text}")*

*print(f"После стемминга: {stemmed}")*

Результат:

Оригинал: Дети бегают по парку и играют на качелях.

После стемминга: Дети бег по парку и игра на качель.


**Объяснение:**

- Стемминг помогает привести все формы слова "бегать" и "играть" к их корням, что может помочь в дальнейшем анализе, например, при классификации текста.




### 7. Анализ частей речи (POS-Tagging) и его использование

Анализ частей речи (POS-tagging) — это процесс определения грамматической категории слова в контексте предложения. Например, важно понять, является ли слово существительным, глаголом, прилагательным или другой частью речи. Это критический этап в морфологической обработке, поскольку правильная интерпретация слов помогает в решении задач, таких как анализ тональности, автоматический перевод, распознавание именованных сущностей и других.

**1. Что такое POS-теггинг?**

POS-теггинг (Part-of-Speech tagging) — это задача, при которой каждому слову в предложении присваивается метка, определяющая его грамматическую категорию. Например, в предложении "Машина быстро едет" нужно определить, что "Машина" — существительное, "быстро" — наречие, а "едет" — глагол.

**2. Как работает POS-теггинг?**

POS-теггинг может быть выполнен с использованием предварительно обученных моделей машинного обучения, которые используют контекст для определения частей речи. Наиболее популярные инструменты для POS-теггинга включают **spaCy** и **nltk**.

**3. Использование библиотеки spaCy для POS-теггинга**

Библиотека **spaCy** предоставляет мощные инструменты для работы с текстами, включая POS-теггинг. Для русского языка необходимо установить модель ru\_core\_news\_sm.



Установка spaCy и модели для русского языка

*pip install spacy*

*python -m spacy download ru\_core\_news\_sm*


Пример POS-теггинга с использованием spaCy:

*import spacy*

*# Загружаем модель для русского языка*

*nlp = spacy.load("ru\_core\_news\_sm")*

*# Пример текста*

*text = "Машина быстро едет по дороге."*

*# Обрабатываем текст*

*doc = nlp(text)*

*# Выводим части речи*

*for token in doc:*

`    `*print(f"Слово: {token.text}, Часть речи: {token.pos\_}")*

Результат:

Слово: Машина, Часть речи: NOUN

Слово: быстро, Часть речи: ADV

Слово: едет, Часть речи: VERB

Слово: по, Часть речи: ADP

Слово: дороге, Часть речи: NOUN

**Объяснение:**

- token.text — это само слово.
- token.pos\_ — это часть речи, определенная для этого слова (например, существительное (NOUN), наречие (ADV), глагол (VERB), предлог (ADP)).


**Преимущества POS-теггинга**
- Позволяет получить полное представление о структуре предложения.
- Ключевое для дальнейших задач, таких как синтаксический анализ, извлечение именованных сущностей и другие.


**Пример использования POS-теггинга для извлечения глаголов**
Предположим, что вам нужно извлечь все глаголы из текста.

*def extract\_verbs(text):*

`    `*"""Извлекает все глаголы из текста."""*

`    `*nlp = spacy.load("ru\_core\_news\_sm")*

`    `*doc = nlp(text)*

`    `*verbs = [token.text for token in doc if token.pos\_ == "VERB"]*

`    `*return verbs*

*# Пример текста*

*text = "Машина быстро едет по дороге, а люди идут в парк."*

*verbs = extract\_verbs(text)*

*print(f"Глаголы: {verbs}")*

Результат:

Глаголы: ['едет', 'идут']

**Объяснение:**

- Функция extract\_verbs проходит по каждому слову в тексте, проверяет его часть речи и, если это глагол (POS = VERB), добавляет его в список.
- Такой подход полезен, если нужно выделить действия, описанные в тексте.

**Преимущества и недостатки POS-теггинга**

**Преимущества:**

- Позволяет точно определить функции слов в предложении.
- Упрощает дальнейшую обработку текста, например, извлечение информации или синтаксический анализ.

**Недостатки:**

- Модели могут ошибаться в случаях с многозначными словами или в контекстах с неоднозначной грамматикой.
- Требует дополнительных вычислительных ресурсов для обучения и применения моделей.


### 8. Разбор морфологических характеристик и применения морфологической обработки

На этом этапе мы рассмотрим более детально, как извлекать и работать с морфологическими характеристиками слов (падеж, число, род, время, лицо и т. д.) и как применять морфологическую обработку в различных реальных задачах, таких как анализ текста и создание чат-ботов.

**1. Разбор морфологических характеристик**

Морфологические характеристики включают:

- **Часть речи** (например, существительное, глагол, прилагательное).
- **Падеж** (для существительных, местоимений, прилагательных).
- **Число** (единственное или множественное).
- **Род** (мужской, женский, средний).
- **Время** (для глаголов — прошедшее, настоящее, будущее).
- **Лицо** (для глаголов — 1-е, 2-е, 3-е лицо).

В библиотеках, таких как **pymorphy2** и **spaCy**, можно извлечь эти характеристики для каждого слова в тексте.

**2. Пример извлечения морфологических характеристик с помощью pymorphy2**

Библиотека **pymorphy2** позволяет не только лемматизировать слова, но и получать их морфологические характеристики.

import pymorphy2

*# Создаем объект MorphAnalyzer*

*morph = pymorphy2.MorphAnalyzer()*

*# Пример слова*

*word = "бегущий"*

*# Разбираем слово*

*parsed\_word = morph.parse(word)[0]  # Берем первый вариант разбора*

*# Выводим морфологические характеристики*

*print(f"Слово: {word}")*

*print(f"Лемма: {parsed\_word.normal\_form}")*

*print(f"Часть речи: {parsed\_word.tag.POS}")*

*print(f"Падеж: {parsed\_word.tag.case}")*

*print(f"Число: {parsed\_word.tag.number}")*

*print(f"Род: {parsed\_word.tag.gender}")*

*print(f"Время: {parsed\_word.tag.tense}")*

*print(f"Лицо: {parsed\_word.tag.person}")*

Результат:

*Слово: бегущий*

*Лемма: бежать*

*Часть речи: VERB*

*Падеж: None*

*Число: sing*

*Род: None*

*Время: pres*

*Лицо: 3*

**Объяснение:**

- normal\_form — лемма (базовая форма) слова.
- POS — часть речи, здесь это глагол (VERB).
- case — падеж, который для глагола отсутствует.
- number — число, в данном случае единственное (sing).
- gender — род, не применяется для глаголов.
- tense — время, настоящее (pres).
- person — лицо, третье (3).

**3. Пример анализа падежей и чисел с помощью pymorphy2**
Допустим, вам нужно проанализировать падежи и числа существительных в тексте.

*def analyze\_case\_and\_number(text):*

`    `*"""Анализирует падеж и число существительных в тексте."""*

`    `*morph = pymorphy2.MorphAnalyzer()*

`    `*words = text.split()*

`    `*results = []*
\*


`    `*for word in words:*

`        `*parsed\_word = morph.parse(word)[0]*

`        `*if parsed\_word.tag.POS == "NOUN":  # Если слово - существительное*

`            `*case = parsed\_word.tag.case*

`            `*number = parsed\_word.tag.number*

`            `*results.append((word, case, number))*
\*


`    `*return results*

*# Пример текста*

*text = "Мальчик и девочка играют в парке."*

*analysis = analyze\_case\_and\_number(text)*

*print(f"Анализ существительных: {analysis}")*

Результат:

Анализ существительных: [('Мальчик', 'nomn', 'sing'), ('девочка', 'nomn', 'sing'), ('парке', 'loca', 'sing')]

**Объяснение:**

- Для каждого существительного мы получаем его падеж (nomn — именительный, loca — местный) и число (sing — единственное).

**4. Применение морфологической обработки в реальных задачах**
**Применение в чат-ботах:** Морфологическая обработка помогает чат-ботам лучше понимать и обрабатывать запросы, выделяя ключевые слова в разных формах. Например, если пользователь пишет "Как я могу купить билет?" и "Как купить билеты?", бот должен распознать, что оба запроса относятся к одной и той же задаче, несмотря на различия в словах.

**Пример использования морфологической обработки в чат-боте:**

*import spacy*

*# Загружаем модель*

*nlp = spacy.load("ru\_core\_news\_sm")*

*def process\_user\_input(user\_input):*

`    `*doc = nlp(user\_input)*
\*


`    `*# Выводим леммы всех слов в запросе*

`    `*lemmatized\_input = [token.lemma\_ for token in doc]*

`    `*return " ".join(lemmatized\_input)*

*# Пример запроса*

*user\_input = "Я хочу купить билет."*

*lemmatized\_input = process\_user\_input(user\_input)*

*print(f"Лемматизированный запрос: {lemmatized\_input}")*

Результат:

Лемматизированный запрос: я хотеть купить билет.

**Объяснение:**

- Для обработки ввода пользователя мы лемматизируем все слова, что позволяет ботам понимать запросы в разных формах.

**5. Применение в поисковых системах**
Морфологическая обработка помогает улучшить результаты поиска, приводя различные формы слов (например, "играть", "играющий", "игра") к одной лемме. Это позволяет пользователю получать более точные результаты поиска.

**Пример использования морфологической обработки для поиска:**

*def search\_documents(query, documents):*

`    `*"""Ищет документы, в которых есть леммы из запроса."""*

`    `*nlp = spacy.load("ru\_core\_news\_sm")*

`    `*query\_doc = nlp(query)*

`    `*query\_lemmas = set([token.lemma\_ for token in query\_doc])*
\*


`    `*matching\_documents = []*

`    `*for doc in documents:*

`        `*doc\_lemmas = set([token.lemma\_ for token in nlp(doc)])*

`        `*if query\_lemmas & doc\_lemmas:  # Если есть пересечение лемм*

`            `*matching\_documents.append(doc)*
\*


`    `*return matching\_documents*

*# Пример документов*

*documents = [*

`    `*"Как правильно играть в футбол.",*

`    `*"Техника игры на гитаре.",*

`    `*"Введение в программирование."*

*]*

*# Пример запроса*

*query = "игра"*

*matching\_docs = search\_documents(query, documents)*

*print(f"Найденные документы: {matching\_docs}")*

Результат:

Найденные документы: ['Как правильно играть в футбол.', 'Техника игры на гитаре.']

**Объяснение:**

- Для каждого документа и запроса лемматизируем текст, а затем проверяем, есть ли пересечение лемм в запросе и документе.














